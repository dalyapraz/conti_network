{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports necessary functions from our functions library and other useful libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import find_users, time_parser\n",
    "import networkx as nx\n",
    "import datetime\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializes our NetworkX Graph and adds a node for each user. \n",
    "Users are found by pulling usernames from the text file users.txt. This file contains all recorded users from the chat logs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph() \n",
    "Users = find_users('user_lists/users.txt')\n",
    "G.add_nodes_from(Users)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we find interactions. This function will create a JSON object that records each user as a sender key. Each of these user's (user1) will have all of the other users (user2) as receiving keys, and the values recorded will be the timestamp of every message sent from user1 to user2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_chat_timestamps():\n",
    "    chat_logs = time_parser('logs/chat_logs.json')\n",
    "    jabber_logs = time_parser('logs/jabber_logs.json')\n",
    "    messages = {}\n",
    "    with open('user_lists/users.txt') as f:\n",
    "        users = f.read().splitlines()\n",
    "    for i in users:\n",
    "        messages[i] = {}\n",
    "    for i in chat_logs:\n",
    "        sender = i['from']\n",
    "        receiver = i['to']\n",
    "        if receiver in messages[sender].keys():\n",
    "            messages[sender][receiver].append(i['ts'])\n",
    "        else: \n",
    "            messages[sender][receiver] = [i['ts']]\n",
    "    for i in jabber_logs:\n",
    "        sender = i['from']\n",
    "        receiver = i['to']\n",
    "        if receiver in messages[sender].keys():\n",
    "            messages[sender][receiver].append(i['ts'])\n",
    "        else: \n",
    "            messages[sender][receiver] = [i['ts']]\n",
    "    for i in messages.keys():\n",
    "        for j in messages[i].keys():\n",
    "            messages[i][j] = sorted(messages[i][j])\n",
    "    return messages\n",
    "interactions = all_chat_timestamps()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will add edges based on meaningful conversations. First, we check to see if both users interact with each other. If they do, we store all of the timestamps of their interactions and use this to extract conversations. A \"conversation\" in our context is messages exchanged where both users are engaging (sending messages) and doing so within a certain time window. We use the number of conversations between two users to establish the weight of the edge between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_conversation(interaction_dict):\n",
    "    interactions = []\n",
    "    users = []\n",
    "    for i in interaction_dict.keys():\n",
    "        interactions += interaction_dict[i]\n",
    "        users.append(i)\n",
    "    if len(users) == 1:\n",
    "        user1 = users[0]\n",
    "        user2 = users[0]\n",
    "    else:\n",
    "        user1 = users[0]\n",
    "        user2 = users[1]\n",
    "    interactions.sort()\n",
    "    conversations = []\n",
    "    init_interaction = interactions[0]\n",
    "    if init_interaction in interaction_dict[user1]:\n",
    "        sender2 = user2\n",
    "    else:\n",
    "        sender2 = user1\n",
    "    check_users = False\n",
    "    if user1 == user2: check_users = True\n",
    "    for i in range(len(interactions)-1):\n",
    "        delta_new = interactions[i+1]-interactions[i]\n",
    "        if interactions[i+1] in interaction_dict[sender2]:\n",
    "            check_users = True\n",
    "        if delta_new > datetime.timedelta(hours=8) and check_users:\n",
    "            end_interaction = interactions[i+1]\n",
    "            conversations.append([init_interaction, end_interaction])\n",
    "            if i == len(interactions)-2:\n",
    "                break\n",
    "            init_interaction = interactions[i+2]\n",
    "    return conversations\n",
    "\n",
    "def generate_edges(interactions):\n",
    "    for user1 in interactions.keys():\n",
    "        for user2 in interactions[user1].keys():\n",
    "            inter1 = interactions[user1][user2]\n",
    "            if user2 in interactions.keys():\n",
    "                if user1 in interactions[user2].keys():\n",
    "                    inter2 = interactions[user2][user1]\n",
    "                else:\n",
    "                    inter2 = []\n",
    "            else: inter2 = []\n",
    "            both = {user1:inter1, user2:inter2}\n",
    "            wgt = len(extract_conversation(both))\n",
    "            if wgt > 0:\n",
    "                G.add_edge(user1, user2, key='edge', weight = wgt)\n",
    "generate_edges(interactions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple normalization function, to superimpose a series of values over [0, 1]. We will use this to compute social score to ensure equal weighting of each feature we have selected to use for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(dictionary):\n",
    "    n = min(dictionary.values())\n",
    "    m = max(dictionary.values())\n",
    "    for i in dictionary.keys():\n",
    "        dictionary[i] = (dictionary[i]-n) / (m-n)\n",
    "    return dictionary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compute the values for each user's attributes. Each attribute has its own dictionary, where the users are the keys and the determined value is stored (after normalization). All attributes are calculated using the networkx library of functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scipy/__init__.py:149: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.15.2\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "user_cliques = {}\n",
    "degrees = G.degree()\n",
    "degrees_dict = {}\n",
    "for i in degrees:\n",
    "    degrees_dict[i[0]] = i[1]\n",
    "degrees_dict = normalize(degrees_dict)\n",
    "betweeness_centrality_dict = normalize(nx.betweenness_centrality(G))\n",
    "degree_centrality_dict = normalize(nx.degree_centrality(G))\n",
    "hubs_authorities = normalize(nx.hits(G)[0])\n",
    "user_clustering_coefficient = {}\n",
    "user_shortest_path = {}\n",
    "for node in Users:\n",
    "    user_cliques[node] = len(nx.cliques_containing_node(G, node))\n",
    "    cur_clustering_coefficient = nx.clustering(G, nodes = node)\n",
    "    user_clustering_coefficient[node] = cur_clustering_coefficient\n",
    "    shortest_path = nx.shortest_path_length(G, source=node).values()\n",
    "    shortest_path_val = sum(shortest_path) / (len(shortest_path))\n",
    "    user_shortest_path[node] = shortest_path_val\n",
    "user_clustering_coefficient = normalize(user_clustering_coefficient)\n",
    "user_shortest_path = normalize(user_shortest_path)\n",
    "user_cliques = normalize(user_cliques)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can calculate the social score. To do so, we iterate through each user and add together all of the associated values from each attribute dictionary. Then, we find the average (since the attributes are currently equally weighted) and store the final score in a dictionary with the user as the key. After we have found each user's score, we sort the dictionary based off social score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_score = {}\n",
    "for u in Users:\n",
    "    social_score[u] = ((degrees_dict[u] + betweeness_centrality_dict[u] + degree_centrality_dict[u] + hubs_authorities[u] + user_clustering_coefficient[u] + user_shortest_path[u] + user_cliques[u])/7)*100\n",
    "social_score = dict(sorted(social_score.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create a Pandas dataframe to store our social score values in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(social_score, orient='index', columns = ['Social Score'])\n",
    "df[\"Degree\"] = pd.Series(degrees_dict)\n",
    "df[\"Betweeness Centrality\"] = pd.Series(betweeness_centrality_dict)\n",
    "df[\"Degree Centrality\"] = pd.Series(degree_centrality_dict)\n",
    "df[\"Hubs/Authorities Score\"] = pd.Series(hubs_authorities)\n",
    "df[\"Clustering Coefficient\"] = pd.Series( user_clustering_coefficient)\n",
    "df[\"Average Shortest Path\"] = pd.Series(user_shortest_path)\n",
    "df[\"Number of Cliques\"] = pd.Series(user_cliques)\n",
    "#display(df[399:])\n",
    "pd.DataFrame.to_csv(df, path_or_buf=\"score.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also will store our final graph in a .gexf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, 'conti_meaningful.gexf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we trying to calculate the structural equvalence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the structural equivalence classes\n",
    "same_neighbors = (lambda u, v: u not in G[v] and v not in G[u] and G[u] == G[v])\n",
    "equivalence_classes = nx.equivalence_classes(G, same_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'fox'}),\n",
       " frozenset({'specter'}),\n",
       " frozenset({'forum'}),\n",
       " frozenset({'globus'}),\n",
       " frozenset({'boby'}),\n",
       " frozenset({'hors'}),\n",
       " frozenset({'mushroom'}),\n",
       " frozenset({'hitech', 'page'}),\n",
       " frozenset({'mavelek'}),\n",
       " frozenset({'terry'}),\n",
       " frozenset({'steller'}),\n",
       " frozenset({'qwerty'}),\n",
       " frozenset({'green'}),\n",
       " frozenset({'alert', 'longer', 'moms', 'muhoboi', 'summit'}),\n",
       " frozenset({'buri'}),\n",
       " frozenset({'ivanalert'}),\n",
       " frozenset({'kaktus'}),\n",
       " frozenset({'deploy'}),\n",
       " frozenset({'tiktak'}),\n",
       " frozenset({'driver'}),\n",
       " frozenset({'forus', 'shaper', 'sirafim'}),\n",
       " frozenset({'voron'}),\n",
       " frozenset({'ponetre'}),\n",
       " frozenset({'admintest'}),\n",
       " frozenset({'taker'}),\n",
       " frozenset({'morisson'}),\n",
       " frozenset({'atlant'}),\n",
       " frozenset({'b2zbrzj5sljbmemgfqnn7zlarduyjhvjwt'}),\n",
       " frozenset({'ahtyng'}),\n",
       " frozenset({'sentinel'}),\n",
       " frozenset({'best'}),\n",
       " frozenset({'shell'}),\n",
       " frozenset({'bourbon'}),\n",
       " frozenset({'baly'}),\n",
       " frozenset({'cobdoctor'}),\n",
       " frozenset({'demon'}),\n",
       " frozenset({'total'}),\n",
       " frozenset({'atlas'}),\n",
       " frozenset({'begemot'}),\n",
       " frozenset({'mult'}),\n",
       " frozenset({'ed'}),\n",
       " frozenset({'larry'}),\n",
       " frozenset({'salamandra'}),\n",
       " frozenset({'poll'}),\n",
       " frozenset({'van'}),\n",
       " frozenset({'fatboy'}),\n",
       " frozenset({'zulas'}),\n",
       " frozenset({'miguel'}),\n",
       " frozenset({'johnyboy77'}),\n",
       " frozenset({'nevada'}),\n",
       " frozenset({'azot'}),\n",
       " frozenset({'carter'}),\n",
       " frozenset({'modar'}),\n",
       " frozenset({'spoon'}),\n",
       " frozenset({'skywalker'}),\n",
       " frozenset({'dino'}),\n",
       " frozenset({'firefox333'}),\n",
       " frozenset({'licor'}),\n",
       " frozenset({'tilar'}),\n",
       " frozenset({'ttrr'}),\n",
       " frozenset({'sticks'}),\n",
       " frozenset({'alarm2'}),\n",
       " frozenset({'dick'}),\n",
       " frozenset({'elon'}),\n",
       " frozenset({'tatarin'}),\n",
       " frozenset({'twin'}),\n",
       " frozenset({'santi'}),\n",
       " frozenset({'dandis'}),\n",
       " frozenset({'serp'}),\n",
       " frozenset({'tom'}),\n",
       " frozenset({'bekeeper'}),\n",
       " frozenset({'dominik'}),\n",
       " frozenset({'hash'}),\n",
       " frozenset({'many'}),\n",
       " frozenset({'wertu'}),\n",
       " frozenset({'mozart'}),\n",
       " frozenset({'chip'}),\n",
       " frozenset({'buran'}),\n",
       " frozenset({'bullet'}),\n",
       " frozenset({'cherry'}),\n",
       " frozenset({'ali'}),\n",
       " frozenset({'derekson'}),\n",
       " frozenset({'kagas'}),\n",
       " frozenset({'troy'}),\n",
       " frozenset({'zloysobaka'}),\n",
       " frozenset({'batka'}),\n",
       " frozenset({'gorec'}),\n",
       " frozenset({'modnik'}),\n",
       " frozenset({'0x00lord',\n",
       "            'ahtung',\n",
       "            'air',\n",
       "            'airbnb1',\n",
       "            'alaska',\n",
       "            'aloxa',\n",
       "            'alter',\n",
       "            'alto',\n",
       "            'badboy',\n",
       "            'balzak',\n",
       "            'baron',\n",
       "            'baxter',\n",
       "            'beny',\n",
       "            'bestofthebest',\n",
       "            'billgeizh',\n",
       "            'black',\n",
       "            'blood',\n",
       "            'bob',\n",
       "            'booker',\n",
       "            'born',\n",
       "            'bra',\n",
       "            'btdpnqwg2nqkqceetqnn7zlarduyjhvjwt',\n",
       "            'buggati',\n",
       "            'buh',\n",
       "            'calmar',\n",
       "            'cameron',\n",
       "            'caution',\n",
       "            'cesar',\n",
       "            'chaos',\n",
       "            'child',\n",
       "            'chrom',\n",
       "            'cicada',\n",
       "            'cnn',\n",
       "            'cooler',\n",
       "            'craft',\n",
       "            'creamsod',\n",
       "            'cuba',\n",
       "            'dallas',\n",
       "            'dandmen',\n",
       "            'dantis',\n",
       "            'def',\n",
       "            'delta',\n",
       "            'demetrius',\n",
       "            'dereksupp',\n",
       "            'doctor',\n",
       "            'domovoy',\n",
       "            'duke',\n",
       "            'dylan',\n",
       "            'efrain',\n",
       "            'eleos',\n",
       "            'eleoslin',\n",
       "            'elvis',\n",
       "            'expex',\n",
       "            'exploit.im',\n",
       "            'fasker',\n",
       "            'fergus',\n",
       "            'fff',\n",
       "            'finn',\n",
       "            'fire',\n",
       "            'fischer',\n",
       "            'flint',\n",
       "            'fly',\n",
       "            'focus',\n",
       "            'food',\n",
       "            'frank',\n",
       "            'freebeer',\n",
       "            'front',\n",
       "            'frost',\n",
       "            'fury',\n",
       "            'gentleman',\n",
       "            'germes',\n",
       "            'gideon777',\n",
       "            'glad',\n",
       "            'goga',\n",
       "            'good',\n",
       "            'good_place',\n",
       "            'gram',\n",
       "            'gringo',\n",
       "            'grossman',\n",
       "            'grover',\n",
       "            'gucci',\n",
       "            'hod',\n",
       "            'hookahplace',\n",
       "            'hopkins',\n",
       "            'horse',\n",
       "            'host',\n",
       "            'ilon',\n",
       "            'inat',\n",
       "            'info',\n",
       "            'inkognito',\n",
       "            'jafar',\n",
       "            'jax',\n",
       "            'jora',\n",
       "            'joynses',\n",
       "            'kerberos',\n",
       "            'keykey',\n",
       "            'killer',\n",
       "            'kintaro',\n",
       "            'kolin',\n",
       "            'kurt',\n",
       "            'loadsupport1',\n",
       "            'loadsupport2',\n",
       "            'loft',\n",
       "            'log',\n",
       "            'lom',\n",
       "            'lucas',\n",
       "            'macros',\n",
       "            'marcus',\n",
       "            'mario',\n",
       "            'mark',\n",
       "            'mashroom',\n",
       "            'matiz',\n",
       "            'mavalek',\n",
       "            'mavelak',\n",
       "            'max17',\n",
       "            'miner',\n",
       "            'mitzi',\n",
       "            'moon',\n",
       "            'mops',\n",
       "            'morgan',\n",
       "            'nek',\n",
       "            'nick',\n",
       "            'odw5mdwotufuxxrgw3pvqjjuze3e33bylylkl667h4nefwiimwqsumyd.onion',\n",
       "            'oldtimes',\n",
       "            'oliver',\n",
       "            'ololoenko',\n",
       "            'olsen',\n",
       "            'oscar',\n",
       "            'packman',\n",
       "            'painkiller',\n",
       "            'panda',\n",
       "            'parker',\n",
       "            'perry',\n",
       "            'phantom',\n",
       "            'pin2',\n",
       "            'pincus',\n",
       "            'pineapple',\n",
       "            'private',\n",
       "            'proffjeck',\n",
       "            'project_talk',\n",
       "            'q3mcco35auwcstmt.onion',\n",
       "            'qwerqwerqwerqwer',\n",
       "            'redmond',\n",
       "            'redroom',\n",
       "            'rooty',\n",
       "            'rox',\n",
       "            'salmon21',\n",
       "            'sandy',\n",
       "            'saulgdmn',\n",
       "            'savage',\n",
       "            'seven300',\n",
       "            'shamm',\n",
       "            'shark',\n",
       "            'slojno',\n",
       "            'slon',\n",
       "            'snow',\n",
       "            'soul',\n",
       "            'star',\n",
       "            'stefan',\n",
       "            'stigg',\n",
       "            'support-100',\n",
       "            'taobao',\n",
       "            'taur',\n",
       "            'test',\n",
       "            'tibone',\n",
       "            'trumen',\n",
       "            'trump',\n",
       "            'tunotif',\n",
       "            'twinq3mcco35auwcstmt.onion',\n",
       "            'twister',\n",
       "            'v1cev1',\n",
       "            'valemy',\n",
       "            'vang',\n",
       "            'verchunls',\n",
       "            'vertu',\n",
       "            'victor',\n",
       "            'vjud.q3mcco35auwcstmt.onion',\n",
       "            'watson',\n",
       "            'weav',\n",
       "            'winston',\n",
       "            'workman1',\n",
       "            'workman2',\n",
       "            'wowddoz',\n",
       "            'xargs',\n",
       "            'xenkee',\n",
       "            'xnull',\n",
       "            'xxx',\n",
       "            'ÑÑ‚Ğ¾Ğ²'}),\n",
       " frozenset({'professor'}),\n",
       " frozenset({'mavemat'}),\n",
       " frozenset({'chain'}),\n",
       " frozenset({'tiniles'}),\n",
       " frozenset({'meatball'}),\n",
       " frozenset({'pin'}),\n",
       " frozenset({'admu'}),\n",
       " frozenset({'bio'}),\n",
       " frozenset({'lemur'}),\n",
       " frozenset({'xoc'}),\n",
       " frozenset({'fast'}),\n",
       " frozenset({'defender'}),\n",
       " frozenset({'cert'}),\n",
       " frozenset({'baraka'}),\n",
       " frozenset({'marsel'}),\n",
       " frozenset({'rozetka'}),\n",
       " frozenset({'void'}),\n",
       " frozenset({'xmoney'}),\n",
       " frozenset({'noman'}),\n",
       " frozenset({'contisupport'}),\n",
       " frozenset({'grant'}),\n",
       " frozenset({'target'}),\n",
       " frozenset({'cosmos'}),\n",
       " frozenset({'buza'}),\n",
       " frozenset({'admin'}),\n",
       " frozenset({'braun'}),\n",
       " frozenset({'ceram'}),\n",
       " frozenset({'naned'}),\n",
       " frozenset({'elvira'}),\n",
       " frozenset({'romanov_2'}),\n",
       " frozenset({'forest'}),\n",
       " frozenset({'price'}),\n",
       " frozenset({'hof'}),\n",
       " frozenset({'darc'}),\n",
       " frozenset({'revers'}),\n",
       " frozenset({'ghost'}),\n",
       " frozenset({'idgo'}),\n",
       " frozenset({'master'}),\n",
       " frozenset({'frog'}),\n",
       " frozenset({'sega'}),\n",
       " frozenset({'doloto'}),\n",
       " frozenset({'netwalker'}),\n",
       " frozenset({'sonar'}),\n",
       " frozenset({'impact', 'netman'}),\n",
       " frozenset({'max'}),\n",
       " frozenset({'starfall'}),\n",
       " frozenset({'kramer'}),\n",
       " frozenset({'brom'}),\n",
       " frozenset({'cheesecake'}),\n",
       " frozenset({'wind'}),\n",
       " frozenset({'bash'}),\n",
       " frozenset({'nik-da'}),\n",
       " frozenset({'paranoik'}),\n",
       " frozenset({'grom'}),\n",
       " frozenset({'sunday'}),\n",
       " frozenset({'subzero'}),\n",
       " frozenset({'zolotoy'}),\n",
       " frozenset({'boba'}),\n",
       " frozenset({'alarm'}),\n",
       " frozenset({'casper'}),\n",
       " frozenset({'barmen'}),\n",
       " frozenset({'grajdanin'}),\n",
       " frozenset({'jumbo'}),\n",
       " frozenset({'blackjob'}),\n",
       " frozenset({'guava'}),\n",
       " frozenset({'kent'}),\n",
       " frozenset({'mors'}),\n",
       " frozenset({'tunri'}),\n",
       " frozenset({'8383', 'song', 'werka'}),\n",
       " frozenset({'nuggets'}),\n",
       " frozenset({'urbanone'}),\n",
       " frozenset({'kerasid'}),\n",
       " frozenset({'romanov'}),\n",
       " frozenset({'baget'}),\n",
       " frozenset({'tnt'}),\n",
       " frozenset({'merch'}),\n",
       " frozenset({'doomsday'}),\n",
       " frozenset({'tramp'}),\n",
       " frozenset({'axel'}),\n",
       " frozenset({'cybergangster'}),\n",
       " frozenset({'dollar'}),\n",
       " frozenset({'bezdar'}),\n",
       " frozenset({'toris'}),\n",
       " frozenset({'grafin'}),\n",
       " frozenset({'leo'}),\n",
       " frozenset({'staff'}),\n",
       " frozenset({'mango'}),\n",
       " frozenset({'talar'}),\n",
       " frozenset({'cany'}),\n",
       " frozenset({'grand'}),\n",
       " frozenset({'gold'}),\n",
       " frozenset({'sharn'}),\n",
       " frozenset({'derek'}),\n",
       " frozenset({'dorirus'}),\n",
       " frozenset({'porovoz'}),\n",
       " frozenset({'ganesh'}),\n",
       " frozenset({'strix'}),\n",
       " frozenset({'veron'}),\n",
       " frozenset({'david'}),\n",
       " frozenset({'bumer'}),\n",
       " frozenset({'clipper'}),\n",
       " frozenset({'reshaev'}),\n",
       " frozenset({'cruz'}),\n",
       " frozenset({'fog'}),\n",
       " frozenset({'bentley'}),\n",
       " frozenset({'flip'}),\n",
       " frozenset({'sepvilk'}),\n",
       " frozenset({'duna'}),\n",
       " frozenset({'dylon'}),\n",
       " frozenset({'revan'}),\n",
       " frozenset({'neo'}),\n",
       " frozenset({'gus'}),\n",
       " frozenset({'stern'}),\n",
       " frozenset({'swift'}),\n",
       " frozenset({'macallan'}),\n",
       " frozenset({'zevs'}),\n",
       " frozenset({'ford'}),\n",
       " frozenset({'mont'}),\n",
       " frozenset({'forbes', 'git', 'goodwin', 'kolbasa'}),\n",
       " frozenset({'hlor'}),\n",
       " frozenset({'kevin'}),\n",
       " frozenset({'band'}),\n",
       " frozenset({'logan'}),\n",
       " frozenset({'gm'}),\n",
       " frozenset({'electronic'}),\n",
       " frozenset({'mentos'}),\n",
       " frozenset({'quite'}),\n",
       " frozenset({'qwertycatt'}),\n",
       " frozenset({'pumba'}),\n",
       " frozenset({'prizrak'}),\n",
       " frozenset({'kran'}),\n",
       " frozenset({'answer'}),\n",
       " frozenset({'tort'}),\n",
       " frozenset({'spider'}),\n",
       " frozenset({'stakan'}),\n",
       " frozenset({'huanivan', 'merlin'}),\n",
       " frozenset({'xenon'}),\n",
       " frozenset({'andy'}),\n",
       " frozenset({'golova'}),\n",
       " frozenset({'graf'}),\n",
       " frozenset({'bonen'}),\n",
       " frozenset({'vampire'}),\n",
       " frozenset({'viper'}),\n",
       " frozenset({'beta'}),\n",
       " frozenset({'ramon'}),\n",
       " frozenset({'bill'}),\n",
       " frozenset({'bloodrush'}),\n",
       " frozenset({'love'}),\n",
       " frozenset({'skippy'}),\n",
       " frozenset({'steve'}),\n",
       " frozenset({'dove'}),\n",
       " frozenset({'muchacho'}),\n",
       " frozenset({'koncord', 'urban'}),\n",
       " frozenset({'rand'}),\n",
       " frozenset({'clickclack'}),\n",
       " frozenset({'klaus'}),\n",
       " frozenset({'sand'}),\n",
       " frozenset({'kingston'})}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equivalence_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
